{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# # Logistic polarity classification\n",
    "\"\"\" AIT726 Final project - Part 1 - Logictic polarity Classification using Logictic regrssion Algorithm on SemEvalâ€™16 dataset ( 1708 training dataset and 587 testing dataset ) and Foursquare ( 849 testing dataset ) \n",
    "\n",
    "Authors: Yasas, Prashanti, Ashwini \n",
    "\n",
    "Command to run the file: run logictic_polarity_classification.ipynb\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from absa.config import DATA_PATHS\n",
    "from absa.dataset import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "# Pass sentences through spacy nlp pipeline and get the output terms\n",
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \"\"\"Load and display semeval16 training dataset\n",
    "   \n",
    "   Load - Load dataset using load_dataset method ( Reads formatted XML file from the provided path )\n",
    "   \n",
    "   Polarity is also read along with aspect\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1004293:0</td>\n",
       "      <td>Judging from previous posts this used to be a ...</td>\n",
       "      <td>RESTAURANT#GENERAL</td>\n",
       "      <td>[negative]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1004293:1</td>\n",
       "      <td>We, there were four of us, arrived at noon - t...</td>\n",
       "      <td>SERVICE#GENERAL</td>\n",
       "      <td>[negative]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1004293:2</td>\n",
       "      <td>They never brought us complimentary noodles, i...</td>\n",
       "      <td>SERVICE#GENERAL</td>\n",
       "      <td>[negative]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1004293:3</td>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>FOOD#QUALITY</td>\n",
       "      <td>[negative]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1004293:3</td>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>FOOD#STYLE_OPTIONS</td>\n",
       "      <td>[negative]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text  \\\n",
       "0  1004293:0  Judging from previous posts this used to be a ...   \n",
       "1  1004293:1  We, there were four of us, arrived at noon - t...   \n",
       "2  1004293:2  They never brought us complimentary noodles, i...   \n",
       "3  1004293:3  The food was lousy - too sweet or too salty an...   \n",
       "4  1004293:3  The food was lousy - too sweet or too salty an...   \n",
       "\n",
       "             category    polarity  \n",
       "0  RESTAURANT#GENERAL  [negative]  \n",
       "1     SERVICE#GENERAL  [negative]  \n",
       "2     SERVICE#GENERAL  [negative]  \n",
       "3        FOOD#QUALITY  [negative]  \n",
       "4  FOOD#STYLE_OPTIONS  [negative]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds_path = DATA_PATHS['asba.semeval16.raw.train']\n",
    "\n",
    "df_train = load_dataset(train_ds_path)\n",
    "\n",
    "df_train = df_train.loc[:, ['id', 'text', 'category', 'polarity']]\n",
    "\n",
    "df_train = pd.DataFrame({\n",
    "    'polarity': df_train.groupby(['id', 'text', 'category'])['polarity'].apply(list),\n",
    "}).reset_index()\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\"\"\"As we have multiple aspects we have used MultiLabelBinarizer to create y_train\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " ...\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2258, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "y_train = mlb.fit_transform(df_train.polarity)\n",
    "print(y_train)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def lemmatize(x):\n",
    "    return ' '.join([token.lemma_ for token in nlp(x)])\n",
    "\n",
    "def select_column(df, column):\n",
    "    return df.loc[:, column].values\n",
    "\n",
    "\n",
    "def reshape_array(array, shape):\n",
    "    return array.reshape(*shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"\"\" Feature extraction: \n",
    "    Select sentences and perform Text Vectorization using TF-IDF (Ngrams considered - Unigram, bigram and trigram)\n",
    "    Select aspect and perform encoding using OneHotEncoder()\n",
    "    Later a featureunion of both results are performed \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2258, 28603)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = make_union(\n",
    "    make_pipeline(\n",
    "        FunctionTransformer(select_column, kw_args={'column': 'text'}),\n",
    "        TfidfVectorizer(preprocessor=lemmatize, ngram_range=(1, 3)),\n",
    "    ),\n",
    "    make_pipeline(\n",
    "        FunctionTransformer(select_column, kw_args={'column': 'category'}),\n",
    "        FunctionTransformer(reshape_array, kw_args={'shape': (-1, 1)}),\n",
    "        OneHotEncoder(),\n",
    "    ),\n",
    ")\n",
    "\n",
    "x_train = pipeline.fit_transform(df_train).toarray()\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validatation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\"\"\" multiclass/multilabel Gaussian Naive Bayes model is used to train semeval training dataset with 3-fold                     cross validation.\n",
    "\n",
    "Respective precision_micro, recall_micro and f1_micro scores are presented \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro Precision Score\t 0.7071820823138862\n",
      "Micro Recall Score\t 0.6721022270411442\n",
      "Micro F1 Score\t\t 0.6891870824742394\n"
     ]
    }
   ],
   "source": [
    "scoring = ['precision_micro', 'recall_micro', 'f1_micro']\n",
    "\n",
    "clf = OneVsRestClassifier(LogisticRegression())\n",
    "\n",
    "scores = cross_validate(clf, x_train, y_train, scoring=scoring, cv=3)\n",
    "\n",
    "print('Micro Precision Score\\t', np.average(scores['test_precision_micro']))\n",
    "print('Micro Recall Score\\t', np.average(scores['test_recall_micro']))\n",
    "print('Micro F1 Score\\t\\t', np.average(scores['test_f1_micro']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\"\"\"Model fit\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='auto',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=None,\n",
       "                                                 solver='lbfgs', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"Load and display semeval16 testing dataset\n",
    "   \n",
    "   Load - Load dataset using load_dataset method ( Reads formatted XML file from the provided path )\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_ds_path = DATA_PATHS['asba.semeval16.raw.test.gold']\n",
    "\n",
    "df_test = load_dataset(test_ds_path)\n",
    "\n",
    "df_test = df_test.loc[:, ['id', 'text', 'category', 'polarity']]\n",
    "\n",
    "df_test = pd.DataFrame({\n",
    "    'polarity': df_test.groupby(['id', 'text', 'category'])['polarity'].apply(list),\n",
    "}).reset_index()\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\" Predict the results on semval2016 testing dataset \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Testing\n",
    "x_test = pipeline.transform(df_test).toarray()\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_true = mlb.transform(df_test.polarity)\n",
    "\n",
    "y_true.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\" Evaluate the results for semval2016 testing dataset \"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "('f1_score', f1_score(y_true, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\" Export results to an excel for performing error Analysis \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "train_pred = cross_val_predict(clf, x_train, y_train, cv=5)\n",
    "\n",
    "prds = mlb.inverse_transform(train_pred)\n",
    "\n",
    "df_train['predictions'] = [list(x) for x in prds]\n",
    "\n",
    "df_train.to_excel('./output/sc_lr.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foursquare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"Load and display Foursquare testing dataset\n",
    "   \n",
    "   Load - Load dataset using load_dataset method ( Reads formatted XML file from the provided path )\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_fs_ds_path = DATA_PATHS['asba.foursquare.raw.test.gold']\n",
    "\n",
    "df_test_fs = load_dataset(test_fs_ds_path)\n",
    "\n",
    "df_test_fs = df_test_fs.loc[:, ['id', 'text', 'category', 'polarity']]\n",
    "\n",
    "df_test_fs = pd.DataFrame({\n",
    "    'polarity': df_test_fs.groupby(['id', 'text', 'category'])['polarity'].apply(list),\n",
    "}).reset_index()\n",
    "\n",
    "df_test_fs.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\"\"\" Predict the results on Foursquare testing dataset \"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Testing\n",
    "x_test_fs = pipeline.transform(df_test_fs).toarray()\n",
    "\n",
    "y_pred_fs = clf.predict(x_test_fs)\n",
    "\n",
    "y_pred_fs.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_true_fs = mlb.transform(df_test_fs.polarity)\n",
    "\n",
    "y_true.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\"\"\" Evaluate the results for Foursquare testing dataset \"\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "('f1_score', f1_score(y_true_fs, y_pred_fs, average='micro'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "('f1_score', f1_score(y_true_fs, y_pred_fs, average='micro'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_ds_path = DATA_PATHS['asba.semeval16.raw.test.gold']\n",
    "\n",
    "df_test = load_dataset(test_ds_path)\n",
    "\n",
    "df_test = df_test.loc[:, ['id', 'text', 'category', 'polarity']]\n",
    "\n",
    "df_test = pd.DataFrame({\n",
    "    'polarity': df_test.groupby(['id', 'text', 'category'])['polarity'].apply(list),\n",
    "}).reset_index()\n",
    "\n",
    "df_test.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\"\"\" Predict the results on semval2016 testing dataset \"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Testing\n",
    "x_test = pipeline.transform(df_test).toarray()\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "y_pred.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_true = mlb.transform(df_test.polarity)\n",
    "\n",
    "y_true.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\"\"\" Evaluate the results for semval2016 testing dataset \"\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "('f1_score', f1_score(y_true, y_pred, average='micro'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Error analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\"\"\" Export results to an excel for performing error Analysis \"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "train_pred = cross_val_predict(clf, x_train, y_train, cv=5)\n",
    "\n",
    "prds = mlb.inverse_transform(train_pred)\n",
    "\n",
    "df_train['predictions'] = [list(x) for x in prds]\n",
    "\n",
    "df_train.to_excel('./output/sc_lr.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Foursquare dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\"\"\"Load and display Foursquare testing dataset\n",
    "   \n",
    "   Load - Load dataset using load_dataset method ( Reads formatted XML file from the provided path )\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_fs_ds_path = DATA_PATHS['asba.foursquare.raw.test.gold']\n",
    "\n",
    "df_test_fs = load_dataset(test_fs_ds_path)\n",
    "\n",
    "df_test_fs = df_test_fs.loc[:, ['id', 'text', 'category', 'polarity']]\n",
    "\n",
    "df_test_fs = pd.DataFrame({\n",
    "    'polarity': df_test_fs.groupby(['id', 'text', 'category'])['polarity'].apply(list),\n",
    "}).reset_index()\n",
    "\n",
    "df_test_fs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\" Predict the results on Foursquare testing dataset \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Testing\n",
    "x_test_fs = pipeline.transform(df_test_fs).toarray()\n",
    "\n",
    "y_pred_fs = clf.predict(x_test_fs)\n",
    "\n",
    "y_pred_fs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_true_fs = mlb.transform(df_test_fs.polarity)\n",
    "\n",
    "y_true.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\" Evaluate the results for Foursquare testing dataset \"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "('f1_score', f1_score(y_true_fs, y_pred_fs, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "('f1_score', f1_score(y_true_fs, y_pred_fs, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>en_BlueRibbonSushi_478218171:0</td>\n",
       "      <td>Yum!</td>\n",
       "      <td>FOOD#QUALITY</td>\n",
       "      <td>[positive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>en_BlueRibbonSushi_478218171:1</td>\n",
       "      <td>Serves really good sushi.</td>\n",
       "      <td>FOOD#QUALITY</td>\n",
       "      <td>[positive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>en_BlueRibbonSushi_478218171:2</td>\n",
       "      <td>Not the biggest portions but adequate.</td>\n",
       "      <td>FOOD#STYLE_OPTIONS</td>\n",
       "      <td>[neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>en_BlueRibbonSushi_478218171:3</td>\n",
       "      <td>Green Tea creme brulee is a must!</td>\n",
       "      <td>FOOD#QUALITY</td>\n",
       "      <td>[positive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>en_BlueRibbonSushi_478218171:4</td>\n",
       "      <td>Don't leave the restaurant without it.</td>\n",
       "      <td>FOOD#QUALITY</td>\n",
       "      <td>[positive]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id                                    text  \\\n",
       "0  en_BlueRibbonSushi_478218171:0                                    Yum!   \n",
       "1  en_BlueRibbonSushi_478218171:1               Serves really good sushi.   \n",
       "2  en_BlueRibbonSushi_478218171:2  Not the biggest portions but adequate.   \n",
       "3  en_BlueRibbonSushi_478218171:3       Green Tea creme brulee is a must!   \n",
       "4  en_BlueRibbonSushi_478218171:4  Don't leave the restaurant without it.   \n",
       "\n",
       "             category    polarity  \n",
       "0        FOOD#QUALITY  [positive]  \n",
       "1        FOOD#QUALITY  [positive]  \n",
       "2  FOOD#STYLE_OPTIONS   [neutral]  \n",
       "3        FOOD#QUALITY  [positive]  \n",
       "4        FOOD#QUALITY  [positive]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds_path = DATA_PATHS['asba.semeval16.raw.test.gold']\n",
    "\n",
    "df_test = load_dataset(test_ds_path)\n",
    "\n",
    "df_test = df_test.loc[:, ['id', 'text', 'category', 'polarity']]\n",
    "\n",
    "df_test = pd.DataFrame({\n",
    "    'polarity': df_test.groupby(['id', 'text', 'category'])['polarity'].apply(list),\n",
    "}).reset_index()\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\" Predict the results on semval2016 testing dataset \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(743, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing\n",
    "x_test = pipeline.transform(df_test).toarray()\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(743, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = mlb.transform(df_test.polarity)\n",
    "\n",
    "y_true.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\" Evaluate the results for semval2016 testing dataset \"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('f1_score', 0.7768707482993198)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "('f1_score', f1_score(y_true, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\" Export results to an excel for performing error Analysis \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './output/sc_lr.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-98fcfa96afd7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'predictions'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./output/sc_lr.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, encoding, inf_rep, verbose, freeze_panes)\u001b[0m\n\u001b[0;32m   2254\u001b[0m             \u001b[0mstartcol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstartcol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2255\u001b[0m             \u001b[0mfreeze_panes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfreeze_panes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2256\u001b[1;33m             \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2257\u001b[0m         )\n\u001b[0;32m   2258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\excel.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine)\u001b[0m\n\u001b[0;32m    740\u001b[0m         )\n\u001b[0;32m    741\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mneed_save\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 742\u001b[1;33m             \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_xlsxwriter.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    193\u001b[0m         \"\"\"\n\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     def write_cells(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xlsxwriter\\workbook.py\u001b[0m in \u001b[0;36mclose\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfileclosed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfileclosed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_store_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xlsxwriter\\workbook.py\u001b[0m in \u001b[0;36m_store_workbook\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m         xlsx_file = ZipFile(self.filename, \"w\", compression=ZIP_DEFLATED,\n\u001b[1;32m--> 655\u001b[1;33m                             allowZip64=self.allow_zip64)\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m         \u001b[1;31m# Add XML sub-files to the Zip file with their Excel filename.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel)\u001b[0m\n\u001b[0;32m   1202\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1203\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1204\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1205\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1206\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './output/sc_lr.xlsx'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "train_pred = cross_val_predict(clf, x_train, y_train, cv=5)\n",
    "\n",
    "prds = mlb.inverse_transform(train_pred)\n",
    "\n",
    "df_train['predictions'] = [list(x) for x in prds]\n",
    "\n",
    "df_train.to_excel('./output/sc_lr.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foursquare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"Load and display Foursquare testing dataset\n",
    "   \n",
    "   Load - Load dataset using load_dataset method ( Reads formatted XML file from the provided path )\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fs_ds_path = DATA_PATHS['asba.foursquare.raw.test.gold']\n",
    "\n",
    "df_test_fs = load_dataset(test_fs_ds_path)\n",
    "\n",
    "df_test_fs = df_test_fs.loc[:, ['id', 'text', 'category', 'polarity']]\n",
    "\n",
    "df_test_fs = pd.DataFrame({\n",
    "    'polarity': df_test_fs.groupby(['id', 'text', 'category'])['polarity'].apply(list),\n",
    "}).reset_index()\n",
    "\n",
    "df_test_fs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\" Predict the results on Foursquare testing dataset \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "x_test_fs = pipeline.transform(df_test_fs).toarray()\n",
    "\n",
    "y_pred_fs = clf.predict(x_test_fs)\n",
    "\n",
    "y_pred_fs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_fs = mlb.transform(df_test_fs.polarity)\n",
    "\n",
    "y_true.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\" Evaluate the results for Foursquare testing dataset \"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "('f1_score', f1_score(y_true_fs, y_pred_fs, average='micro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [
     "#%\n"
    ],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}