{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from absa.config import DATA_PATHS\n",
    "from absa.dataset import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_ds_path = DATA_PATHS['asba.semeval16.raw.train']\n",
    "\n",
    "df_train = load_dataset(train_ds_path)\n",
    "\n",
    "df_train = df_train.loc[:, ['id', 'text', 'category', 'polarity']]\n",
    "\n",
    "df_train = pd.DataFrame({\n",
    "    'polarity': df_train.groupby(['id', 'text', 'category'])['polarity'].apply(list),\n",
    "}).reset_index()\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "y_train = mlb.fit_transform(df_train.polarity)\n",
    "print(y_train)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def lemmatize(x):\n",
    "    return ' '.join([token.lemma_ for token in nlp(x)])\n",
    "\n",
    "def select_column(df, column):\n",
    "    return df.loc[:, column].values\n",
    "\n",
    "\n",
    "def reshape_array(array, shape):\n",
    "    return array.reshape(*shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = make_union(\n",
    "    make_pipeline(\n",
    "        FunctionTransformer(select_column, kw_args={'column': 'text'}),\n",
    "        TfidfVectorizer(preprocessor=lemmatize, stop_words='english', ngram_range=(1, 3)),\n",
    "    ),\n",
    "    make_pipeline(\n",
    "        FunctionTransformer(select_column, kw_args={'column': 'category'}),\n",
    "        FunctionTransformer(reshape_array, kw_args={'shape': (-1, 1)}),\n",
    "        OneHotEncoder(),\n",
    "    ),\n",
    ")\n",
    "\n",
    "x_train = pipeline.fit_transform(df_train).toarray()\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validatation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scoring = ['precision_micro', 'recall_micro', 'f1_micro']\n",
    "\n",
    "clf = OneVsRestClassifier(LogisticRegression())\n",
    "\n",
    "scores = cross_validate(clf, x_train, y_train, scoring=scoring, cv=3)\n",
    "\n",
    "print('Micro Precision Score\\t', np.average(scores['test_precision_micro']))\n",
    "print('Micro Recall Score\\t', np.average(scores['test_recall_micro']))\n",
    "print('Micro F1 Score\\t\\t', np.average(scores['test_f1_micro']))\n",
    "\n",
    "# -----------------------------------------\n",
    "\n",
    "# Without #AspectCategory As Feature\n",
    "\n",
    "# Micro Precision Score\t 0.569311128799821\n",
    "# Micro Recall Score\t 0.5921557834734619\n",
    "# Micro F1 Score\t\t 0.5804751685040593\n",
    "\n",
    "# -----------------------------------------\n",
    "\n",
    "# With #AspectCategory as Feature\n",
    "\n",
    "# Micro Precision Score\t 0.5703663218941576\n",
    "# Micro Recall Score\t 0.5917189114769569\n",
    "# Micro F1 Score\t\t 0.5808142238635255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_ds_path = DATA_PATHS['asba.semeval16.raw.test.gold']\n",
    "\n",
    "df_test = load_dataset(test_ds_path)\n",
    "\n",
    "df_test = df_test.loc[:, ['id', 'text', 'category', 'polarity']]\n",
    "\n",
    "df_test = pd.DataFrame({\n",
    "    'polarity': df_test.groupby(['id', 'text', 'category'])['polarity'].apply(list),\n",
    "}).reset_index()\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Testing\n",
    "x_test = pipeline.transform(df_test).toarray()\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_true = mlb.transform(df_test.polarity)\n",
    "\n",
    "y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "('f1_score', f1_score(y_true, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [
     "#%\n"
    ],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}