{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Aspect classification\n",
    "\n",
    "\"\"\"\n",
    "AIT726 Final project - Part 1 - Naive Bayes Aspect Classification using Naive Bayes Algorithm on SemEval’16 dataset ( 1708 training dataset and 587 testing dataset ) and Foursquare ( 849 testing dataset )\n",
    "\n",
    "Authors: Yasas, Prashanti, Ashwini\n",
    "\n",
    "Command to run the file: run aspect_classification.ipynb\n",
    "\n",
    "Flow: \n",
    "Data loading -  For all the restaurant reviews we parsed the XML files and retrieved the reviews for SemEval’16 and foursquare datasets.\n",
    "\n",
    "Preprocessing and Feature Extraction - Tokenization, and lemmatization of reviews is performed to get word tokens and their root words. Text vectorization is then performed using term frequency-inverse document frequency (TF-IDF) vectorizer with a ngram range of 1-3. In addition to TF-IDF features. Moreover, we provided predefined term categories (obtained from a vocabulary file) for each word in the input review sentence as features for aspect classification. \n",
    " \n",
    "Baseline Models: Naive Bayes Classifier \n",
    "\n",
    "Cross-Validation and Error Analysis: Performed five-fold cross-validation on the training data and performed the error analysis using the predictions obtained in cross-validation. \n",
    "\n",
    "Train Models: Trained the models using the optimal hyper-parameters explored in the cross validation process on the whole training dataset. \n",
    "\n",
    "Evaluation: Evaluated the trained models on the test data (SemEval’16 and Foursquare datasets)\n",
    "\n",
    "Note : For more details please check README file\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"\"\" Imported all required libraries \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from absa.config import DATA_PATHS\n",
    "from absa.dataset import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Pass sentences through spacy nlp pipeline and get the output terms\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "#Create a list of stopwords \n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"\"\"Load and display semeval16 training dataset\n",
    "       Load - Load dataset using load_dataset method ( Reads formatted XML file from the provided path )\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_ds_path = DATA_PATHS['asba.semeval16.raw.train']\n",
    "\n",
    "df_train = load_dataset(train_ds_path)\n",
    "\n",
    "df_train = pd.DataFrame({\n",
    "    'text': df_train.groupby('id')['text'].first(),\n",
    "    'categories': df_train.groupby('id')['category'].apply(list),\n",
    "})\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"\"\"Create lookup dictionary using the vocabulary.txt ( In this Vocabulary we have mappings of words to aspect                  categories ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lookup = {}\n",
    "with open('../resources/vocabulary.txt', 'r', encoding='utf-8') as f:\n",
    "    for idx, section in enumerate(f.read().split('\\n\\n')):\n",
    "        for key in section.split('\\n'):\n",
    "            lookup[key.lower()] = idx\n",
    "lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"\"\" find_terms - Looks for categories for each word in the sentence \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def find_terms(sents):\n",
    "    for sent in sents:\n",
    "        term_keys = {}\n",
    "        for key in lookup.keys():\n",
    "            if key in sent.lower():\n",
    "                if lookup[key] not in term_keys:\n",
    "                    term_keys[lookup[key]] = 0\n",
    "                term_keys[lookup[key]] += 1\n",
    "        yield term_keys\n",
    "\n",
    "#list(find_terms(['Pizza was too hot!']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "    \"\"\" lemmatize  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def lemmatize(x):\n",
    "    return ' '.join([token.lemma_ for token in nlp(x)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"\"\" Feature extraction - Text Vectorization using TF-IDF (Ngrams considered - Unigram, bigram and trigram)\n",
    "        The obtained key value pairs are vectorized using DictVectorizer. Later a featureunion of both results are \n",
    "        performed \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = make_union(\n",
    "    # Stopwords: Keep/Remove - Removed as part of error analysis\n",
    "    # Lemmatize: Yes\n",
    "    TfidfVectorizer(preprocessor=lemmatize, ngram_range=(1, 3)),\n",
    "    make_pipeline(\n",
    "        FunctionTransformer(lambda x: list(find_terms(x))),\n",
    "        DictVectorizer()\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "#Generate the training dataset\n",
    "x_train = pipeline.fit_transform(df_train.text).toarray()\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"\"\"As we have multiple aspects we have used MultiLabelBinarizer to create y_train\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "y_train = mlb.fit_transform(df_train.categories)\n",
    "\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validatation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"\"\" multiclass/multilabel Gaussian Naive Bayes model is used to train semeval training dataset with 5-fold                     cross validation. Respective precision_micro, recall_micro and f1_micro scores are presented \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scoring = ['precision_micro', 'recall_micro', 'f1_micro']\n",
    "\n",
    "clf = OneVsRestClassifier(GaussianNB())\n",
    "\n",
    "scores = cross_validate(clf, x_train, y_train, scoring=scoring, cv=5)\n",
    "\n",
    "print('Micro Precision Score\\t', np.average(scores['test_precision_micro']))\n",
    "print('Micro Recall Score\\t', np.average(scores['test_recall_micro']))\n",
    "print('Micro F1 Score\\t\\t', np.average(scores['test_f1_micro']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"\"\" Export results to an excel for performing error Analysis \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_pred = cross_val_predict(clf, x_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prds = mlb.inverse_transform(train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_train['predictions'] = [list(x) for x in prds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_train.to_excel('./output/ac_nb.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "    \"\"\"Model fit\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"\"\"Load and display semeval16 testing dataset\n",
    "       Load - Load dataset using load_dataset method ( Reads formatted XML file from the provided path )\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_ds_path = DATA_PATHS['asba.semeval16.raw.test.gold']\n",
    "\n",
    "df_test = load_dataset(test_ds_path)\n",
    "\n",
    "df_test = pd.DataFrame({\n",
    "    'text': df_test.groupby('id')['text'].first(),\n",
    "    'categories': df_test.groupby('id')['category'].apply(list),\n",
    "})\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "    \"\"\" Predict the results on semval2016 testing dataset \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Testing\n",
    "x_test = pipeline.transform(df_test.text).toarray()\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_true = mlb.transform(df_test.categories)\n",
    "\n",
    "y_true.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "    \"\"\" Evaluate the results for semval2016 testing dataset \"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "('f1_score', f1_score(y_true, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foursquare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"\"\"Load and display Foursquare testing dataset\n",
    "       Load - Load dataset using load_dataset method ( Reads formatted XML file from the provided path )\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_fs_ds_path = DATA_PATHS['asba.foursquare.raw.test.gold']\n",
    "\n",
    "df_test_fs = load_dataset(test_fs_ds_path)\n",
    "\n",
    "df_test_fs = pd.DataFrame({\n",
    "    'text': df_test_fs.groupby('id')['text'].first(),\n",
    "    'categories': df_test_fs.groupby('id')['category'].apply(list),\n",
    "})\n",
    "\n",
    "df_test_fs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"\"\" Predict the results on Foursquare testing dataset \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Testing\n",
    "x_test_fs = pipeline.transform(df_test_fs.text).toarray()\n",
    "\n",
    "y_pred_fs = clf.predict(x_test_fs)\n",
    "\n",
    "y_pred_fs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_true_fs = mlb.transform(df_test_fs.categories)\n",
    "\n",
    "y_true_fs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"\"\" Evaluate the results for Foursquare testing dataset \"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "('f1_score', f1_score(y_true_fs, y_pred_fs, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}